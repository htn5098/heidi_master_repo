#!/bin/bash
#PBS -l nodes=1:ppn=15
#PBS -l pmem=10gb
#PBS -l walltime=02:00:00
#PBS -A cxc693_a_t_sc_default
#PBS -j oe
#PBS -N MACAV2_extr #MACAV2 GCM processing for ETo calcualtion

# Loading modules
module purge
module load r
module load gcc/5.3.1
module load parallel/20170522

# Export to a tmp folder with more space
ulimit -u unlimited
export TMPDIR=/storage/home/htn5098/scratch/tmpBigdata #to avoid running out of space when running jobs in parallel

echo "Job started on `hostname` at `date`"
START=$(date +%s)

# Go to the directory
cd /storage/home/htn5098/work/DataAnalysis/src/jobs/

# Information of GCM, period and variable
gcm=BNU-ESM #$gcm
period=historical #$period
interimpath=/storage/home/htn5098/scratch/DataAnalysis/data/interim/ #$interimpath
# source=$source
var=(tasmax tasmin rhsmax rhsmin uas vas rsds) # pr
# yearstart=$yearstart
# yearend=$yearend
# chunk=$PBS_ARRAYID

#Rscript ../Rcodes/CWDSERC_extract_climdata.R $gcm $period $yearstart $yearend $interimpath $source $chunk

parallel --jobs 2 Rscript ../Rcodes/CWDSERC_extract_climdata.R $interimpath $gcm $period ::: ${var[@]}

echo "Extracting ends at `date`"
END=$(date +%s)
sec=$((END-START))
min=$((sec/60))
echo "Time elapsed: $sec seconds"